{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Translation with Tensor Flow\n",
    "\n",
    "## Introduction\n",
    "\n",
    "[Background on neural networks](https://en.wikipedia.org/wiki/Feedforward_neural_network)\n",
    "\n",
    "[Background on recurrent neural networks.](https://en.wikipedia.org/wiki/Long_short-term_memory)\n",
    "\n",
    "### Implementation\n",
    "\n",
    "First load in all the libraries we'll need. Several of the usual suspects but also Tensor Flow and Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set a few global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LSTM_NODES = 256\n",
    "NUM_SENTENCES = 20000\n",
    "MAX_SENTENCE_LENGTH = 50\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load in the Spanish Dataset. There isn't much data processing needed with this data set. Just need two copies of the translated sentence: one with the start-of-sentence token (typically `sos`) and the other with the end-of-sentence `eos` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples input: 20000\n",
      "num samples output: 20000\n",
      "num samples output input: 20000\n"
     ]
    }
   ],
   "source": [
    "# The English sentences\n",
    "input_sentences = []\n",
    "# The Spanish sentences\n",
    "output_sentences = []\n",
    "# modified Spanish with start of sentence tags\n",
    "output_sentences_inputs = []\n",
    "\n",
    "count = 0\n",
    "for line in open(r'./spa.txt', encoding=\"utf-8\"):\n",
    "    count += 1\n",
    "\n",
    "    if count > NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    # english, spanish, attribution (last variable isn't used.)\n",
    "    input_sentence, output, _ = line.rstrip().split('\\t')\n",
    "\n",
    "    output_sentence = output + ' <eos>'\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"num samples input:\", len(input_sentences))\n",
    "print(\"num samples output:\", len(output_sentences))\n",
    "print(\"num samples output input:\", len(output_sentences_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Collecting and organizing the data. The seq2seq architecture is an encoder-decoder architecture which consists of two LSTM networks: the encoder LSTM and the decoder LSTM. The input to the encoder LSTM is the sentence in the original language; the input to the decoder LSTM is the sentence in the translated language with a start-of-sentence token. The output is the actual target sentence with an end-of-sentence token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 3753\n",
      "Length of longest sentence in input: 6\n",
      "Total unique words in the output: 10493\n",
      "Length of longest sentence in the output: 11\n",
      "encoder_input_sequences.shape: (20000, 6)\n",
      "encoder_input_sequences[155]: [ 0  0  0  0 49 66]\n",
      "7\n",
      "3\n",
      "decoder_input_sequences.shape: (20000, 11)\n",
      "decoder_input_sequences[155]: [   2 4638    0    0    0    0    0    0    0    0    0]\n",
      "2\n",
      "475\n",
      "913\n"
     ]
    }
   ],
   "source": [
    "# Tokenizes and converts words to sequences\n",
    "\n",
    "# input sentences\n",
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
    "\n",
    "# output sentences\n",
    "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)\n",
    "\n",
    "# All sequences need to be the same length (same # of LSTM layers), so we have to pad many sequences\n",
    "# The encoder pads sentences at the beginning\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)\n",
    "print(\"encoder_input_sequences[155]:\", encoder_input_sequences[155])\n",
    "\n",
    "# Word to index mapping (so we know what # corresponds to what word)\n",
    "print(word2idx_inputs[\"i'm\"])\n",
    "print(word2idx_inputs[\"you\"])\n",
    "\n",
    "# The decoder pads sentences at the end\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
    "print(\"decoder_input_sequences[155]:\", decoder_input_sequences[155])\n",
    "\n",
    "# Getting the labels (the decoder!)\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "\n",
    "print(word2idx_outputs[\"<sos>\"])\n",
    "print(word2idx_outputs[\"gracias\"])\n",
    "print(word2idx_outputs[\"mujeres\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.090436   0.19636    0.29474   -0.47706   -0.80436    0.3078\n",
      " -0.55205    0.58453   -0.17056   -0.84846    0.19528    0.23671\n",
      "  0.46827   -0.58977   -0.12163   -0.24697   -0.072944   0.17259\n",
      " -0.0485     0.9527     0.50629    0.58497   -0.19367   -0.45459\n",
      " -0.031095   0.51633   -0.24052   -0.1007     0.53627    0.024225\n",
      " -0.50162    0.73692    0.49468   -0.34744    0.89337    0.057439\n",
      " -0.19127    0.39333    0.21182   -0.89837    0.078704  -0.16344\n",
      "  0.45261   -0.41096   -0.19499   -0.13489   -0.016313  -0.021849\n",
      "  0.17136   -1.2413     0.079503  -0.91144    0.35699    0.36289\n",
      " -0.24934   -2.1196     0.14534    0.52964    0.90134    0.033603\n",
      "  0.022809   0.70625   -1.0362    -0.59809    0.70592   -0.072793\n",
      "  0.67033    0.52763   -0.47807   -0.67374    0.36632   -0.38284\n",
      " -0.10349   -0.6402     0.18104    0.82568    0.066403  -0.40791\n",
      " -0.083813  -0.36487    0.045362  -0.073527  -0.20117    0.37441\n",
      " -1.4024    -0.25605   -0.4708    -0.16145   -0.87921   -0.36325\n",
      " -0.17357   -0.077983   0.43273    0.0089295 -1.0316    -0.11589\n",
      " -0.34524    0.11514   -0.40812    0.20203  ]\n",
      "[-0.14524999 -0.35109001 -0.24270999 -0.033816    0.10984     0.024604\n",
      " -0.18661     0.097345   -0.081843    0.1174      0.64248002 -0.32789999\n",
      "  0.11123    -0.22217    -0.13759001 -0.59364998  0.52314001  0.04563\n",
      " -0.71929002 -0.31937     0.53239     0.78112     0.76643002  0.81238002\n",
      "  0.32506001 -0.44635999 -0.061012   -0.81702     0.22445001  0.51058\n",
      " -0.33970001  0.71323001 -0.20630001  0.43715    -0.27384001  0.092513\n",
      "  0.10865    -0.26501    -0.25694001  0.11714    -0.59972    -1.01300001\n",
      " -0.31336999 -0.52726001  0.37448001  0.059976   -0.12698001  0.1612\n",
      "  1.11099994 -0.54276001 -0.25628    -0.046812    0.31145999  1.08010006\n",
      " -0.34487    -2.28609991 -0.71837002 -0.65548998  0.87379998  0.46173\n",
      " -0.053813    1.13660002 -0.29762    -0.1779      0.47260001 -0.047153\n",
      " -0.11591     0.36201    -0.027457    0.94628    -0.17668    -0.30215001\n",
      " -0.59919    -0.72776002  0.10371    -0.27761     0.0063904   0.087078\n",
      " -0.17817999 -0.12182    -0.22943     0.16892999 -0.28593001  0.20821001\n",
      " -0.37382001 -0.29943001  0.36019999 -0.42423001 -0.29881001 -0.057871\n",
      " -0.46055999 -0.27421001  0.23163     0.68506998 -1.14059997 -0.0033004\n",
      "  0.11194     0.44284001  0.55255002 -0.18037   ]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open(r'./glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = zeros((num_words, EMBEDDING_SIZE))\n",
    "for word, index in word2idx_inputs.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "\n",
    "print(embeddings_dictionary[\"happy\"])\n",
    "print(embedding_matrix[539])\n",
    "\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
    "decoder_targets_one_hot = np.zeros((\n",
    "        len(input_sentences),\n",
    "        max_out_len,\n",
    "        num_words_output\n",
    "    ),\n",
    "    dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 11, 10494)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 13:59:30.636094: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "print(decoder_targets_one_hot.shape)\n",
    "for i, d in enumerate(decoder_output_sequences):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1\n",
    "\n",
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(LSTM_NODES, return_state=True)\n",
    "\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "encoder_states = [h, c]\n",
    "\n",
    "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "282/282 [==============================] - 67s 225ms/step - loss: 2.1845 - accuracy: 0.7152 - val_loss: 2.2761 - val_accuracy: 0.6926\n",
      "Epoch 2/20\n",
      "282/282 [==============================] - 66s 235ms/step - loss: 1.6735 - accuracy: 0.7627 - val_loss: 2.0176 - val_accuracy: 0.7245\n",
      "Epoch 3/20\n",
      "282/282 [==============================] - 68s 243ms/step - loss: 1.4678 - accuracy: 0.7895 - val_loss: 1.8848 - val_accuracy: 0.7443\n",
      "Epoch 4/20\n",
      "282/282 [==============================] - 84s 297ms/step - loss: 1.3347 - accuracy: 0.8065 - val_loss: 1.7806 - val_accuracy: 0.7571\n",
      "Epoch 5/20\n",
      "282/282 [==============================] - 81s 286ms/step - loss: 1.2336 - accuracy: 0.8190 - val_loss: 1.7197 - val_accuracy: 0.7679\n",
      "Epoch 6/20\n",
      "282/282 [==============================] - 88s 311ms/step - loss: 1.1544 - accuracy: 0.8296 - val_loss: 1.6880 - val_accuracy: 0.7721\n",
      "Epoch 7/20\n",
      "282/282 [==============================] - 90s 318ms/step - loss: 1.0880 - accuracy: 0.8389 - val_loss: 1.6448 - val_accuracy: 0.7759\n",
      "Epoch 8/20\n",
      "282/282 [==============================] - 94s 332ms/step - loss: 1.0295 - accuracy: 0.8467 - val_loss: 1.6527 - val_accuracy: 0.7732\n",
      "Epoch 9/20\n",
      "282/282 [==============================] - 94s 335ms/step - loss: 0.9813 - accuracy: 0.8536 - val_loss: 1.6273 - val_accuracy: 0.7764\n",
      "Epoch 10/20\n",
      "282/282 [==============================] - 92s 325ms/step - loss: 0.9409 - accuracy: 0.8600 - val_loss: 1.6435 - val_accuracy: 0.7768\n",
      "Epoch 11/20\n",
      "282/282 [==============================] - 88s 313ms/step - loss: 0.9035 - accuracy: 0.8658 - val_loss: 1.6397 - val_accuracy: 0.7762\n",
      "Epoch 12/20\n",
      "282/282 [==============================] - 92s 326ms/step - loss: 0.8731 - accuracy: 0.8707 - val_loss: 1.6301 - val_accuracy: 0.7776\n",
      "Epoch 13/20\n",
      "282/282 [==============================] - 91s 322ms/step - loss: 0.8472 - accuracy: 0.8754 - val_loss: 1.6238 - val_accuracy: 0.7802\n",
      "Epoch 14/20\n",
      "282/282 [==============================] - 90s 319ms/step - loss: 0.8220 - accuracy: 0.8796 - val_loss: 1.6277 - val_accuracy: 0.7795\n",
      "Epoch 15/20\n",
      "282/282 [==============================] - 91s 322ms/step - loss: 0.8012 - accuracy: 0.8834 - val_loss: 1.6476 - val_accuracy: 0.7777\n",
      "Epoch 16/20\n",
      "282/282 [==============================] - 93s 329ms/step - loss: 0.7815 - accuracy: 0.8868 - val_loss: 1.6525 - val_accuracy: 0.7778\n",
      "Epoch 17/20\n",
      "282/282 [==============================] - 90s 318ms/step - loss: 0.7619 - accuracy: 0.8901 - val_loss: 1.6657 - val_accuracy: 0.7769\n",
      "Epoch 18/20\n",
      "282/282 [==============================] - 93s 331ms/step - loss: 0.7454 - accuracy: 0.8932 - val_loss: 1.6874 - val_accuracy: 0.7775\n",
      "Epoch 19/20\n",
      "282/282 [==============================] - 94s 332ms/step - loss: 0.7321 - accuracy: 0.8961 - val_loss: 1.6970 - val_accuracy: 0.7767\n",
      "Epoch 20/20\n",
      "282/282 [==============================] - 94s 332ms/step - loss: 0.7180 - accuracy: 0.8982 - val_loss: 1.7208 - val_accuracy: 0.7760\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "plot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "r = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets_one_hot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
    "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [h, c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "plot_model(decoder_model, to_file='model_plot_dec.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "idx2word_input = {v: k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v: k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq) -> str:\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_out_len):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        target_seq[0, 0] = idx\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: He does not smoke.\n",
      "Response: él no fuma.\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
